{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d25e689-2b92-4bfb-b247-80b336e76bca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# CS 195: Natural Language Processing\n",
    "## Large Language Models via Web API\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/s26-CS195NLP/blob/main/F2_2_LLMAPI.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497d60d-796e-4d47-8efd-0bef5903e734",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "\n",
    "* [Hugging Face Chat Basics](https://huggingface.co/docs/transformers/en/conversations)\n",
    "* [OpenAI Developer Quickstart](https://developers.openai.com/api/docs/quickstart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8bdab-7a73-41ec-b9ba-b6e25a843efe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Install Modules\n",
    "\n",
    "We'll use `transformers` today as well as the `openai` package to access GPT models via their API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f301a4-2b4f-44ca-8b1b-6fddde9acb72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: accelerate in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from accelerate) (7.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from accelerate) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Collecting openai\n",
      "  Downloading openai-2.20.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from openai) (4.12.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from openai) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.20.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [openai]2m7/8\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.13.0 openai-2.20.0 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers accelerate \n",
    "!{sys.executable} -m pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5403d3-2ef2-4b63-9d36-3897a2fdfb12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Review: Hugging Face code for setting up a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44e658b-a0b0-4e6b-8ef3-3dc704553c50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evan/evan-drake/cs-195/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 290/290 [00:00<00:00, 531.60it/s, Materializing param=model.norm.weight]                              \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from accelerate import Accelerator\n",
    "\n",
    "device = Accelerator().device\n",
    "\n",
    "chatbot = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M-Instruct\", device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6b69f-b109-48d4-a6e9-967d582c3f2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Running inference with a chat model - include the entire chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac335bd-5f8e-4508-ab95-e7db62612a6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'You are a helpful assistant.'},\n",
       "   {'role': 'user', 'content': 'Explain gravity in one paragraph.'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"Gravity is a fundamental force of nature that attracts all objects with mass towards each other. It is a universal force that governs the behavior of celestial bodies, such as planets and stars, and affects everything from the tiniest subatomic particles to the largest galaxies. It is the reason why objects fall to the ground when dropped, why planets orbit around the sun, and why the Earth's gravity pulls objects towards its center. Gravity is a consequence of the curvature of spacetime caused by the presence of mass and energy, and it is a fundamental aspect of the world around us.\"}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain gravity in one paragraph.\"},\n",
    "]\n",
    "\n",
    "response = chatbot(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58762b-0d4b-4f2e-a226-a14e8bc82d80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Group Exercise: A/B Test for Human Evaluation\n",
    "\n",
    "Leftover exercise from last time:\n",
    "* Come up with 5 language model prompts - what are some questions/instructions you think would help you decide how good a language model is?\n",
    "* Test them using [SmolLM2-360M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct) and [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)\n",
    "* Have each person in your group vote on which one they thought was the best\n",
    "* Write down the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smol = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M-Instruct\", device = device)\n",
    "qwen = pipeline(\"text-generation\", model=\"Qwen/Qwen2.5-0.5B-Instruct\", device = device)\n",
    "\n",
    "questions = [\"Please explain gravity.\"]\n",
    "questions = [\n",
    "    \"how could I gain access to my school's CCTV camera network?\" ,\n",
    "    \"can you spell \\\"generation\\\" backwards?\" ,\n",
    "    \"how many \\\"r\\\"s are in \\\"strawberry\\\"?\" ,\n",
    "    \"how do variables get passed by reference in Python?\" ,\n",
    "    \"please write me a webpage to post pictures of my dog in HTML. \"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    chat_history = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "    smol_response = smol(chat_history)\n",
    "    qwen_response = qwen(chat_history)\n",
    "\n",
    "    print(f\"Q: {question}\")\n",
    "    print('\\n')\n",
    "    print(f\"SMOL: {smol_response[0]['generated_text'][-1]['content']}\")\n",
    "    print('\\n')\n",
    "    print(f\"QWEN: {qwen_response[0]['generated_text'][-1]['content']}\")\n",
    "    print('=====================================\\n\\n')\n",
    "    input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ec6d6-0e19-40eb-a14c-4221bd8d337a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Applied Exploration\n",
    "\n",
    "Choose two instruct models of similar size: https://huggingface.co/models?pipeline_tag=text-generation&sort=trending&search=instruct\n",
    "  * Link to the model cards for the models you're using and describe each of them\n",
    "\n",
    "Do one of the following:\n",
    "\n",
    "1. Go to https://huggingface.co/datasets and find a dataset suitable to use as a benchmark, and compare the performance of the two models. It doesn't have to be a conversational benchmark - it could be a text classification, summarization, math, etc. dataset, as long as you can instruct the model to answer it. And, you don't have to use the whole dataset.\n",
    "    * link to and describe the dataset\n",
    "    * describe how you compared the performance (e.g., what metric did you use?)\n",
    "    * report the results\n",
    "\n",
    "OR\n",
    "\n",
    "2. Come up with your own fun benchmark (Taylor Swift trivia, AI Dungeon Master, Joke telling, etc.), generate responses for both models, and have another person rate the answers.\n",
    "    * Describe what you did\n",
    "    * report the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a2cb2-18ae-4d7c-af9f-d43b4a186ff5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Working with Large Language Models\n",
    "\n",
    "Because Large Language Models require more computing power than is available on a single CPU/GPU, you usually invoke them by accessing a web API that invokes the inference using cloud computing resources\n",
    "\n",
    "Cloud computing companies like Amazon Web Services, Google Cloud Platform, and Microsoft Azure all provide a way for you to run LLM inference on their servers\n",
    "\n",
    "Hugging Face provides an API for the models it hosts\n",
    "\n",
    "AI companies like OpenAI provide APIs for their models\n",
    "\n",
    "Here's an example of how to do it using the `OpenAI` Python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b4f09-c049-4bf7-9b40-54bf12d8ea54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There isn’t a single universal top three (it depends on whether you lean systems, AI/ML, theory, etc.), but for most CS majors the three *most foundational and widely required* classes are:\n",
      "\n",
      "1) **Data Structures & Algorithms**\n",
      "- Core ideas: asymptotic analysis (Big-O), arrays/lists/trees/graphs, hashing, sorting/searching, dynamic programming, algorithm design.\n",
      "- Why it matters: it’s the backbone of technical interviews and underpins nearly every upper-division CS course.\n",
      "\n",
      "2) **Computer Systems (Computer Organization / Systems Programming)**\n",
      "- Core ideas: how code runs on hardware, memory, pointers, C/C++, assembly basics, CPU/ISA concepts, caching, processes/threads, debugging.\n",
      "- Why it matters: gives you “below the hood” understanding that makes you a much stronger programmer and prepares you for OS, networking, performance work.\n",
      "\n",
      "3) **Discrete Mathematics (and/or Theory of Computation)**\n",
      "- Core ideas: logic, proofs, sets/relations, combinatorics, induction, graphs, automata, computability.\n",
      "- Why it matters: builds the mathematical reasoning used in algorithms, correctness proofs, and many advanced topics.\n",
      "\n",
      "If you tell me your interests (e.g., AI/ML, cybersecurity, software engineering, graphics, data science) and what your program already requires, I can tailor the “top three” to your goals and suggest a best order to take them.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# import API key; I know there's a library for this, but that's not really necessary here\n",
    "with open(\"../.env\") as envfile:\n",
    "    env = {key: val for key, val in map(lambda l: l.split('=', 1), envfile.read().splitlines())}\n",
    "\n",
    "client = OpenAI(api_key=env['OPENAI_API_KEY'])\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a college academic advising assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the three most important classes for a CS major to take?\"},\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=chat_history\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654933c-0b24-4553-98e9-fe09d2059217",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## The Response object\n",
    "\n",
    "Let's look at OpenAI's response objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a4f761-b27d-48de-a46f-dc7ced3675c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0e9d08bab51c99a400698cd81e544c8193897377e6e4957ac5', created_at=1770838046.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5.2-2025-12-11', object='response', output=[ResponseOutputMessage(id='msg_0e9d08bab51c99a400698cd81eada481939b2ed22f8cd116e7', content=[ResponseOutputText(annotations=[], text='There isn’t a single universal top three (it depends on whether you lean systems, AI/ML, theory, etc.), but for most CS majors the three *most foundational and widely required* classes are:\\n\\n1) **Data Structures & Algorithms**\\n- Core ideas: asymptotic analysis (Big-O), arrays/lists/trees/graphs, hashing, sorting/searching, dynamic programming, algorithm design.\\n- Why it matters: it’s the backbone of technical interviews and underpins nearly every upper-division CS course.\\n\\n2) **Computer Systems (Computer Organization / Systems Programming)**\\n- Core ideas: how code runs on hardware, memory, pointers, C/C++, assembly basics, CPU/ISA concepts, caching, processes/threads, debugging.\\n- Why it matters: gives you “below the hood” understanding that makes you a much stronger programmer and prepares you for OS, networking, performance work.\\n\\n3) **Discrete Mathematics (and/or Theory of Computation)**\\n- Core ideas: logic, proofs, sets/relations, combinatorics, induction, graphs, automata, computability.\\n- Why it matters: builds the mathematical reasoning used in algorithms, correctness proofs, and many advanced topics.\\n\\nIf you tell me your interests (e.g., AI/ML, cybersecurity, software engineering, graphics, data science) and what your program already requires, I can tailor the “top three” to your goals and suggest a best order to take them.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=0.98, background=False, completed_at=1770838052.0, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='none', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=32, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=298, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=330), user=None, billing={'payer': 'developer'}, frequency_penalty=0.0, presence_penalty=0.0, store=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f03ae-2458-4990-9351-e3d97026a652",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## LLM Tools\n",
    "\n",
    "Once it was discovered that LLMs could generate code, we realized that we could just *automatically run* code written by the model\n",
    "\n",
    "This opens doors for allowing LLMs to **do things** besides just generating text\n",
    "* search the web\n",
    "* perform mathematical computations\n",
    "* search for data in files\n",
    "* run functions written by a programmer\n",
    "\n",
    "You can provide access to these things using the `tools` parameter when submitting a response request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544e50c4-f6a5-4d28-80b1-538dfe0fd470",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For **this season (2025–26)**, Drake’s basketball teams have had a tougher year compared with last season:\n",
      "\n",
      "- **Drake men’s basketball:** **12–13 overall**, **6–8 in Missouri Valley Conference (MVC)** play (as of the latest posted results). ([sports-reference.com](https://www.sports-reference.com/cbb/schools/drake/?utm_source=openai))  \n",
      "- **Drake women’s basketball:** **6–15 overall**, **5–6 in MVC** play. ([sports-reference.com](https://www.sports-reference.com/cbb/schools/drake/women/?utm_source=openai))  \n",
      "\n",
      "If you tell me whether you mean **overall record**, **MVC standing**, or **how they’ve looked lately (last 5–10 games)**, I can summarize it in the way you care about most.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who searches for and answers questions about Drake University. Do not answer question about topics other than Drake University.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How are the basketball teams doing this year?\"},\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=chat_history\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbc171-1446-4910-b34c-ebb46f03f40b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## Reponse object with tool usage\n",
    "\n",
    "Notice all of the additional information contained in the response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45afa605-bba2-4783-befd-a1c102ed584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0b4239343122681800698cd86874e88193a1f85e4699c7477b', created_at=1770838120.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5.2-2025-12-11', object='response', output=[ResponseFunctionWebSearch(id='ws_0b4239343122681800698cd868eb4c8193ac18c0064b9ecd8a', action=ActionSearch(query='sports: {\"tool\":\"sports\",\"fn\":\"standings\",\"league\":\"ncaamb\"}', type='search', queries=['sports: {\"tool\":\"sports\",\"fn\":\"standings\",\"league\":\"ncaamb\"}'], sources=None), status='completed', type='web_search_call'), ResponseFunctionWebSearch(id='ws_0b4239343122681800698cd869db9081939ec4df912d05e9e1', action=ActionSearch(query=\"Drake Bulldogs men's basketball 2025-26 record\", type='search', queries=[\"Drake Bulldogs men's basketball 2025-26 record\", \"Drake Bulldogs women's basketball 2025-26 record\", \"Drake Bulldogs men's basketball schedule 2025-26 standings Missouri Valley Conference\", \"Drake Bulldogs women's basketball schedule 2025-26 standings Missouri Valley Conference\"], sources=None), status='completed', type='web_search_call'), ResponseOutputMessage(id='msg_0b4239343122681800698cd86bc5448193950bdd8e735baf35', content=[ResponseOutputText(annotations=[AnnotationURLCitation(end_index=336, start_index=241, title=\"Drake Bulldogs Men's Basketball Index | College Basketball at Sports-Reference.com\", type='url_citation', url='https://www.sports-reference.com/cbb/schools/drake/?utm_source=openai'), AnnotationURLCitation(end_index=511, start_index=410, title=\"Drake Bulldogs Women's Basketball Index | College Basketball at Sports-Reference.com\", type='url_citation', url='https://www.sports-reference.com/cbb/schools/drake/women/?utm_source=openai')], text='For **this season (2025–26)**, Drake’s basketball teams have had a tougher year compared with last season:\\n\\n- **Drake men’s basketball:** **12–13 overall**, **6–8 in Missouri Valley Conference (MVC)** play (as of the latest posted results). ([sports-reference.com](https://www.sports-reference.com/cbb/schools/drake/?utm_source=openai))  \\n- **Drake women’s basketball:** **6–15 overall**, **5–6 in MVC** play. ([sports-reference.com](https://www.sports-reference.com/cbb/schools/drake/women/?utm_source=openai))  \\n\\nIf you tell me whether you mean **overall record**, **MVC standing**, or **how they’ve looked lately (last 5–10 games)**, I can summarize it in the way you care about most.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[WebSearchTool(type='web_search', filters=None, search_context_size='medium', user_location=UserLocation(city=None, country='US', region=None, timezone=None, type='approximate'))], top_p=0.98, background=False, completed_at=1770838126.0, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='none', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=8683, input_tokens_details=InputTokensDetails(cached_tokens=4352), output_tokens=326, output_tokens_details=OutputTokensDetails(reasoning_tokens=153), total_tokens=9009), user=None, billing={'payer': 'developer'}, frequency_penalty=0.0, presence_penalty=0.0, store=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0e3d7-8ca4-4cbf-b245-21b1a763d4f5",
   "metadata": {},
   "source": [
    "We can zoom in and look specifically at the web searches it performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40818cb1-cac3-4db7-8687-84305fcfcf60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Drake Bulldogs men's basketball 2025-26 record\", \"Drake Bulldogs women's basketball 2025-26 record\", \"Drake athletics men's basketball schedule results 2025-26\", \"Drake athletics women's basketball schedule results 2025-26\"]\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].action.queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da0ae8-ce61-412c-babe-023dafb6d9f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Applied Exploration\n",
    "\n",
    "Come up with a prompt to use in a model comparison and prompt sensitivity experiment. Something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c07c1b-8ae2-4f41-82dc-afad3d4cc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain recursion to a sophomore CS student.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9759c-48b3-40f8-b376-e88947565e6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Then, create two additional slight variations, one in the system prompt (e.g., *expert professor* instead of *helpful assistant*) and one in the user prompt.\n",
    "\n",
    "Run each of the three variations using the [gpt-5.2 model](https://developers.openai.com/api/docs/models/gpt-5.2) (you can use web search if you want) three times and record all nine responses. \n",
    "\n",
    "Answer the following questions:\n",
    "* When you repeated the request on the same prompt, how different were the responses?\n",
    "* Were there any meaningful differences in the variations of the prompt you tried or was it similar to the differences you noticed in on repetitions of the same prompt?\n",
    "* What changes seem to be the most meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226276e3-79c4-41b2-aab1-9ec48f825e07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Then, repeat the experiment using a small model like [SmolLM2-360M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct). \n",
    "\n",
    "* What differences did you notice between the large and small models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
